{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Dangue.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOowklP3Ijkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "df = pd.read_csv('E:\\dangueData.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JvmP4-xIjkw",
        "colab_type": "code",
        "outputId": "8b2e929a-d719-41a4-e74c-4b64a5860f58",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>MIN</th>\n",
              "      <th>MAX</th>\n",
              "      <th>HUMIDITY</th>\n",
              "      <th>RAINFALL</th>\n",
              "      <th>DANGUE</th>\n",
              "      <th>LEVEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>12.993929</td>\n",
              "      <td>25.059539</td>\n",
              "      <td>78.824885</td>\n",
              "      <td>1.286636</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008</td>\n",
              "      <td>2</td>\n",
              "      <td>13.658286</td>\n",
              "      <td>26.383448</td>\n",
              "      <td>72.602956</td>\n",
              "      <td>0.687685</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008</td>\n",
              "      <td>3</td>\n",
              "      <td>20.411250</td>\n",
              "      <td>31.367558</td>\n",
              "      <td>76.903226</td>\n",
              "      <td>0.974194</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008</td>\n",
              "      <td>4</td>\n",
              "      <td>22.771889</td>\n",
              "      <td>34.031619</td>\n",
              "      <td>73.943810</td>\n",
              "      <td>0.980952</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008</td>\n",
              "      <td>5</td>\n",
              "      <td>23.945625</td>\n",
              "      <td>34.171060</td>\n",
              "      <td>77.360369</td>\n",
              "      <td>7.021198</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH        MIN        MAX   HUMIDITY  RAINFALL  DANGUE  LEVEL\n",
              "0  2008      1  12.993929  25.059539  78.824885  1.286636       0      1\n",
              "1  2008      2  13.658286  26.383448  72.602956  0.687685       0      1\n",
              "2  2008      3  20.411250  31.367558  76.903226  0.974194       0      1\n",
              "3  2008      4  22.771889  34.031619  73.943810  0.980952       0      1\n",
              "4  2008      5  23.945625  34.171060  77.360369  7.021198       0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37NNqujjIjkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['MONTH','YEAR','HUMIDITY', 'MIN', 'RAINFALL', 'MAX']]\n",
        "y = df['LEVEL']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtE9W8wAIjk1",
        "colab_type": "code",
        "outputId": "816e1b42-cf18-4004-f21e-b7bbfd8b87ce",
        "colab": {}
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>MIN</th>\n",
              "      <th>MAX</th>\n",
              "      <th>HUMIDITY</th>\n",
              "      <th>RAINFALL</th>\n",
              "      <th>DANGUE</th>\n",
              "      <th>LEVEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>YEAR</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.039341</td>\n",
              "      <td>-0.026401</td>\n",
              "      <td>-0.042889</td>\n",
              "      <td>0.008876</td>\n",
              "      <td>0.335181</td>\n",
              "      <td>0.372338</td>\n",
              "      <td>0.465797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MONTH</th>\n",
              "      <td>-0.039341</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.273338</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.530021</td>\n",
              "      <td>0.021895</td>\n",
              "      <td>0.316265</td>\n",
              "      <td>0.443394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIN</th>\n",
              "      <td>-0.026401</td>\n",
              "      <td>0.273338</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.879903</td>\n",
              "      <td>0.502352</td>\n",
              "      <td>0.231499</td>\n",
              "      <td>0.301316</td>\n",
              "      <td>0.414593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAX</th>\n",
              "      <td>-0.042889</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.879903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.087856</td>\n",
              "      <td>0.064593</td>\n",
              "      <td>0.177811</td>\n",
              "      <td>0.221934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HUMIDITY</th>\n",
              "      <td>0.008876</td>\n",
              "      <td>0.530021</td>\n",
              "      <td>0.502352</td>\n",
              "      <td>0.087856</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.094968</td>\n",
              "      <td>0.275363</td>\n",
              "      <td>0.482472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAINFALL</th>\n",
              "      <td>0.335181</td>\n",
              "      <td>0.021895</td>\n",
              "      <td>0.231499</td>\n",
              "      <td>0.064593</td>\n",
              "      <td>0.094968</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.368675</td>\n",
              "      <td>0.322285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DANGUE</th>\n",
              "      <td>0.372338</td>\n",
              "      <td>0.316265</td>\n",
              "      <td>0.301316</td>\n",
              "      <td>0.177811</td>\n",
              "      <td>0.275363</td>\n",
              "      <td>0.368675</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.862293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEVEL</th>\n",
              "      <td>0.465797</td>\n",
              "      <td>0.443394</td>\n",
              "      <td>0.414593</td>\n",
              "      <td>0.221934</td>\n",
              "      <td>0.482472</td>\n",
              "      <td>0.322285</td>\n",
              "      <td>0.862293</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              YEAR     MONTH       MIN       MAX  HUMIDITY  RAINFALL  \\\n",
              "YEAR      1.000000 -0.039341 -0.026401 -0.042889  0.008876  0.335181   \n",
              "MONTH    -0.039341  1.000000  0.273338  0.084662  0.530021  0.021895   \n",
              "MIN      -0.026401  0.273338  1.000000  0.879903  0.502352  0.231499   \n",
              "MAX      -0.042889  0.084662  0.879903  1.000000  0.087856  0.064593   \n",
              "HUMIDITY  0.008876  0.530021  0.502352  0.087856  1.000000  0.094968   \n",
              "RAINFALL  0.335181  0.021895  0.231499  0.064593  0.094968  1.000000   \n",
              "DANGUE    0.372338  0.316265  0.301316  0.177811  0.275363  0.368675   \n",
              "LEVEL     0.465797  0.443394  0.414593  0.221934  0.482472  0.322285   \n",
              "\n",
              "            DANGUE     LEVEL  \n",
              "YEAR      0.372338  0.465797  \n",
              "MONTH     0.316265  0.443394  \n",
              "MIN       0.301316  0.414593  \n",
              "MAX       0.177811  0.221934  \n",
              "HUMIDITY  0.275363  0.482472  \n",
              "RAINFALL  0.368675  0.322285  \n",
              "DANGUE    1.000000  0.862293  \n",
              "LEVEL     0.862293  1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eznLEWPIjk4",
        "colab_type": "code",
        "outputId": "3c01da14-4785-4802-b67a-f93f05e0ff35",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 134 entries, 0 to 133\n",
            "Data columns (total 8 columns):\n",
            "YEAR        134 non-null int64\n",
            "MONTH       134 non-null int64\n",
            "MIN         134 non-null float64\n",
            "MAX         134 non-null float64\n",
            "HUMIDITY    134 non-null float64\n",
            "RAINFALL    134 non-null float64\n",
            "DANGUE      134 non-null int64\n",
            "LEVEL       134 non-null int64\n",
            "dtypes: float64(4), int64(4)\n",
            "memory usage: 8.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ1Pg-_ZIjk6",
        "colab_type": "code",
        "outputId": "d93bda1e-ed2e-4e1b-c2f8-afdfc973fe7e",
        "colab": {}
      },
      "source": [
        "#logistic regression\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=2)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVKRKsiGIjk9",
        "colab_type": "code",
        "outputId": "dccefbe7-050f-4645-a453-ed985619d45e",
        "colab": {}
      },
      "source": [
        "#logistic regression performance \n",
        "print('Coefficients:', logreg.coef_)\n",
        "print('Intercept:', logreg.intercept_)\n",
        " \n",
        "predictions = logreg.predict(x_test)\n",
        "print('Classification Report:\\n',classification_report(y_test, predictions))\n",
        "\n",
        "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))\n",
        "print('Accuracy Score:',accuracy_score(y_test, predictions))\n",
        "\n",
        "\n",
        "print(\"Precision:\",metrics.precision_score(y_test, predictions,average='micro'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test,predictions,average='micro' ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [[ 3.70054200e-02  6.27485999e-03 -1.97104935e-01  4.56529357e-03\n",
            "  -9.18715864e-02  6.89120425e-02]\n",
            " [-2.43607809e-01 -3.05523618e-03  1.12360365e-01 -1.73913139e-01\n",
            "  -8.47290408e-04  6.09618824e-02]\n",
            " [ 2.16928396e-01 -3.32894483e-03  7.40671690e-02  2.37733972e-01\n",
            "  -6.11414364e-04 -2.47988534e-01]\n",
            " [ 9.60238854e-01 -2.60374904e-02  4.33928855e-01  4.65008931e-01\n",
            "  -1.37366915e-02 -1.69155313e-01]\n",
            " [ 5.09313616e-01 -1.46427375e-02  1.10097875e-01  6.89089145e-02\n",
            "   4.36300719e-03  3.74118144e-01]\n",
            " [ 1.25257444e+00 -3.44553555e-03 -4.57885063e-01  9.04977132e-01\n",
            "   5.53531284e-03  2.75129043e-01]]\n",
            "Intercept: [ 1.22208627e-03 -2.96896671e-03  6.10788908e-05 -2.90762967e-03\n",
            " -5.94417224e-03 -3.38067193e-03]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.33      0.25      0.29        12\n",
            "           2       0.40      0.60      0.48        10\n",
            "           3       1.00      0.50      0.67         4\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.41      0.41      0.41        27\n",
            "   macro avg       0.43      0.34      0.36        27\n",
            "weighted avg       0.44      0.41      0.40        27\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3 9 0 0]\n",
            " [4 6 0 0]\n",
            " [1 0 2 1]\n",
            " [1 0 0 0]]\n",
            "Accuracy Score: 0.4074074074074074\n",
            "Precision: 0.4074074074074074\n",
            "Recall: 0.4074074074074074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbnwA5LgIjk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Classification Tree\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import graphviz\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
        "clf = clf.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dTKI6nOIjlB",
        "colab_type": "code",
        "outputId": "bf600219-f140-47cc-e38e-9ccb59ceeeb9",
        "colab": {}
      },
      "source": [
        "#Classification Tree performance\n",
        "y_pred = clf.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\nAccuracy: {0:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
        "predictions = clf.predict(x_test)\n",
        "print('Confusion Matrix:\\n',confusion_matrix(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.67      1.00      0.80         4\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.89      0.89      0.89        27\n",
            "   macro avg       0.64      0.71      0.67        27\n",
            "weighted avg       0.88      0.89      0.88        27\n",
            "\n",
            "\n",
            "Accuracy: 0.8889\n",
            "Confusion Matrix:\n",
            " [[10  1  1  0]\n",
            " [ 0 10  0  0]\n",
            " [ 0  0  4  0]\n",
            " [ 0  0  1  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK0bG88AIjlD",
        "colab_type": "code",
        "outputId": "f99eb6fa-34aa-4ae8-aab1-96ff82bd20ee",
        "colab": {}
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=3)\n",
        "rf.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
              "            oob_score=False, random_state=3, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF8besVXIjlG",
        "colab_type": "code",
        "outputId": "ccb29c3f-463f-4444-8e1f-7bc1ce681b31",
        "colab": {}
      },
      "source": [
        "#Random forest performance\n",
        "y_pred = rf.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\nAccuracy: {0:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print('Confusion Matrix:\\n',confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.71      1.00      0.83        10\n",
            "           3       1.00      0.75      0.86         4\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.85      0.85      0.85        27\n",
            "   macro avg       0.68      0.65      0.65        27\n",
            "weighted avg       0.86      0.85      0.84        27\n",
            "\n",
            "\n",
            "Accuracy: 0.8519\n",
            "Confusion Matrix:\n",
            " [[10  2  0  0]\n",
            " [ 0 10  0  0]\n",
            " [ 0  1  3  0]\n",
            " [ 0  1  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWmmsHncIjlI",
        "colab_type": "code",
        "outputId": "e20e743d-4117-4102-95ed-95057c8a88f1",
        "colab": {}
      },
      "source": [
        "#Support Vector Machine \n",
        "from sklearn.svm import SVC\n",
        "svmmdl=SVC()\n",
        "svmmdl.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
              "  shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBgEu6lxIjlK",
        "colab_type": "code",
        "outputId": "28ff0716-24be-4dbe-f504-0ee82747377e",
        "colab": {}
      },
      "source": [
        "#Support Vector Machine \n",
        "y_pred=svmmdl.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('\\nAccuracy: {0:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.33      0.47        12\n",
            "           2       0.38      0.80      0.52        10\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.44      0.44      0.44        27\n",
            "   macro avg       0.30      0.28      0.25        27\n",
            "weighted avg       0.50      0.44      0.40        27\n",
            "\n",
            "\n",
            "Accuracy: 0.4444\n",
            "[[4 8 0 0]\n",
            " [1 8 1 0]\n",
            " [0 4 0 0]\n",
            " [0 1 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jh44OsGIjlM",
        "colab_type": "code",
        "outputId": "fc36325d-87e4-43f5-ad0d-ebbcdcd7cc76",
        "colab": {}
      },
      "source": [
        "x = df[['MONTH','YEAR','HUMIDITY', 'MIN', 'RAINFALL', 'MAX']]\n",
        "y = df['LEVEL']\n",
        "from sklearn.linear_model import LinearRegression\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=2)\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "         normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB_ksLXOIjlO",
        "colab_type": "code",
        "outputId": "986f8e38-02c7-4007-fdb2-6a46e1d60161",
        "colab": {}
      },
      "source": [
        "y_pred = linreg.predict(x_test)\n",
        "print('Coefficients:', linreg.coef_)\n",
        "print('Intercept:', linreg.intercept_)\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred ))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred ))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred )))\n",
        "accuracy = linreg.score(x_test,y_test)\n",
        "print('AccuracyII:',accuracy*100,'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [ 0.13426258  0.21285031  0.04909226  0.08768993  0.00122989 -0.00367424]\n",
            "Intercept: -432.6681384586335\n",
            "MAE: 0.5939561242717075\n",
            "MSE: 0.4881846274429147\n",
            "RMSE: 0.6987021020742064\n",
            "AccuracyII: 29.387580673435544 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gptMgd1lIjlQ",
        "colab_type": "code",
        "outputId": "d7c56061-1f1d-47ae-c424-a8c87d5b87ba",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df2.plot(kind='bar',figsize=(60,10))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAADTMAAAJLCAYAAACB2+OoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X2MXmWBxuH7tINOC11MCzHWGqYRsUaxH46RQqsDfoBgSLAxajBQQ0RiWDDs6haIYYgIxCIfGzcYspAucSm7AoWAqzaEvMEFFdpSDTq0hVhCbUQtOrahBYSzf6CN3VY6LX2fF+e5roSEDmfOed7emUATfjlN27YBAAAAAAAAAAAAAAAA6LYJvT4AAAAAAAAAAAAAAAAAUAcxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKCIvm7c9LDDDmsHBga6cevXtC3Pbsm0ydN6fQwKsXdd7F0Xe9fF3nWxd13sXRd718XedbF3XexdF3vXxd51sXdd7F0Xe9fF3nWxd13sXRd718XedbF3XexdF3vXxd51sXddat179erVv2vb9vC9XdeVmGlgYCCrVq3qxq1f04Y7wxkeGu71MSjE3nWxd13sXRd718XedbF3XexdF3vXxd51sXdd7F0Xe9fF3nWxd13sXRd718XedbF3XexdF3vXxd51sXdd7F0Xe9fF3nWpde+maZ4cy3UTun0QAAAAAAAAAAAAAAAAgETMBAAAAAAAAAAAAAAAABQiZgIAAAAAAAAAAAAAAACK6Ov1AQAAAAAAAAAAAAAAAKCbXnjhhWzatCk7duzo+rNOPPTEjIyMdP05vdLf358ZM2bkoIMO2q/vFzMBAAAAAAAAAAAAAAAwrm3atClTpkzJwMBAmqbp6rM2b92c6VOmd/UZvdK2bbZs2ZJNmzZl5syZ+3WPCQf4TAAAAAAAAAAAAAAAAPCasmPHjkybNq3rIdN41zRNpk2b9qrecCVmAgAAAAAAAAAAAAAAYNwTMh0Yr/b3UcwEAAAAAAAAAAAAAAAAFNHX6wMAAAAAAAAAAAAAAABASQNLvntA77fxylPGdN2KFSvy8Y9/PCMjI5k1a9bfvG7ZsmX5yEc+kunTp+/XeTqdTq666qrcc889+/X93eTNTAAAAAAAAAAAAAAAAFDA8uXLs2DBgtx6662veN2yZcuyefPmQqcqS8wEAAAAAAAAAAAAAAAAXbZt27Y88MADufHGG3eJmb7+9a/n6KOPzuzZs7NkyZLcdtttWbVqVU4//fTMmTMn27dvz8DAQH73u98lSVatWpWhoaEkyUMPPZRjjz02c+fOzbHHHpt169b14qPtk75eHwAAAAAAAAAAAAAAAADGuzvvvDMnnXRSjjrqqEydOjVr1qzJ008/nTvvvDM/+clPMnny5DzzzDOZOnVqvvnNb+aqq67K4ODgK95z1qxZuf/++9PX15d77703F110UW6//fZCn2j/iJkAAAAAAAAAAAAAAACgy5YvX54vfvGLSZJPfepTWb58eV566aV89rOfzeTJk5MkU6dO3ad7jo6O5swzz8yGDRvSNE1eeOGFA37uA03MBAAAAAAAAAAAAAAAAF20ZcuW3HfffXn00UfTNE1efPHFNE2TRYsWpWmavX5/X19fXnrppSTJjh07dn79K1/5So4//visWLEiGzduzNDQULc+wgEzodcHAAAAAAAAAAAAAAAAgPHstttuyxlnnJEnn3wyGzduzFNPPZWZM2dm6tSpuemmm/Lss88mSZ555pkkyZQpU7J169ad3z8wMJDVq1cnSW6//fadXx8dHc2b3/zmJMmyZcsKfZpXx5uZAAAAAAAAAAAAAAAAqMrGK08p+rzly5dnyZIlu3xt0aJFGRkZyamnnprBwcG87nWvy8knn5zLL788ixcvzjnnnJNJkyblRz/6US655JKcddZZufzyy/O+971v5z2+/OUv58wzz8zVV1+dE044oehn2l9iJgAAAAAAAAAAAAAAAOiiTqez29fOO++8nX+/p9Bp0aJFO3+9cOHCrF+/frd7zJ8/f5evf/WrX02SDA0NZWho6FWeujsm9PoAAAAAAAAAAAAAAAAAQB3ETAAAAAAAAAAAAAAAAEARY46ZmqaZ2DTNI03T3NPNAwEAAAAAAAAAAAAAAADj0768men8JCPdOggAAAAAAAAAAAAAAAAwvo0pZmqaZkaSU5L8e3ePAwAAAAAAAAAAAAAAAIxXY30z07VJvpzkpS6eBQAAAAAAAAAAAAAAABjHmrZtX/mCpvlYkpPbtv1C0zRDSf65bduP7eG6s5OcnSTT3jTtPefecm4Xjvva1tnYydDAUK+PQSH2rou962Lvuti7Lvaui73rYu+62Lu8a+9d37Nnzzlys70r4ue7Lvaui73rYu+62Lsu9q6Lveti77rYuy72rou962Lvuti7Lvaui73rYu/eO/HQE3PEkUfs/PX0b7zjgN5/8z+N7Pz7rc9tzZTXT9ntmre84S2Z9c5ZefFPL+bItx+Z6751XSZNnrRfz3vwhw/mW//6rdz8nZuz8n9WZv1j63PuBXtueUb/MJoV31mRxZ9bvE/P+Mbl38jBhxycc847Z7d/9uTjT+YHoz/Y5WuXHn/p6rZtB/d2374xPPu4JKc2TXNykv4k/9A0zbfbtv3MX1/Utu0NSW5IksHBwXZ4aHgMtx5fhjvDqfFz18redbF3XexdF3vXxd51sXdd7F0Xe5e37Pvf7dmzhwYetndF/HzXxd51sXdd7F0Xe9fF3nWxd13sXRd718XedbF3XexdF3vXxd51sXdd7N17IyMjmT5letfu/9f33pzNe3zWpEmT8vOf/TxJcvrpp+eu/7wrF1xwwc5/3rZt2rbNhAkT9vq8wyYflv6+/kyfMj2LP7n4Fa99fsvzueWmW3LRBReN8dO8bMrrp+SQ1x+yx88y2j+a4bnDu3zt0lw6pvvu9dO1bXth27Yz2rYdSPKpJPf9/5AJAAAAAAAAAAAAAAAAGJuFCxfm8ccfz8aNG/OOd7wjX/jCFzJv3rw89dRTWblyZebPn5958+blE5/4RLZt25Yk+f73v59Zs2ZlwYIFueOOO3bea9myZTn33JffyvT000/ntNNOy+zZszN79uw8+OCDWbJkSZ544onMmTMnX/rSl5IkS5cuzXvf+968+93vziWXXLLzXl/72tfy9re/PR/60Ieybt26rnz2vadaAAAAAAAAAAAAAAAAwAHxpz/9Kd/73vdy9NFHJ0nWrVuXM844I4888kgOPvjgXHbZZbn33nuzZs2aDA4O5uqrr86OHTvyuc99LnfffXd++MMf5te//vUe733eeeflAx/4QH76059mzZo1eec735krr7wyb33rW7N27dosXbo0K1euzIYNG/LQQw9l7dq1Wb16de6///6sXr06t956ax555JHccccdefjhh7vy+fv25eK2bTtJOl05CQAAAAAAAAAAAAAAAIxT27dvz5w5c5K8/Gams846K5s3b84RRxyRY445Jkny4x//OL/4xS9y3HHHJUmef/75zJ8/P4899lhmzpyZt73tbUmSz3zmM7nhhht2e8Z9992Xm2++OUkyceLEHHroofn973+/yzUrV67MypUrM3fu3CTJtm3bsmHDhmzdujWnnXZaJk+enCQ59dRTu/C7sI8xEwAAAAAAAAAAAAAAALDvJk2alLVr1+729YMPPnjn37dtmw9/+MNZvnz5LtesXbs2TdMckHO0bZsLL7wwn//853f5+rXXXnvAnvFKJnT9CQAAAAAAAAAAAAAAAMBeHXPMMXnggQfy+OOPJ0meffbZrF+/PrNmzcovf/nLPPHEE0myW+z0Fx/84Adz/fXXJ0lefPHF/PGPf8yUKVOydevWndeceOKJuemmm7Jt27Ykya9+9av85je/yfvf//6sWLEi27dvz9atW3P33Xd35TN6MxMAAAAAAAAAAAAAAAB1GR7t9Qn26PDDD8+yZcvy6U9/Os8991yS5LLLLstRRx2VG264IaecckoOO+ywLFiwII8++uhu33/dddfl7LPPzo033piJEyfm+uuvz/z583PcccflXe96Vz760Y9m6dKlGRkZyfz585MkhxxySL797W9n3rx5+eQnP5k5c+bkiCOOyMKFC7vyGcVMAAAAAAAAAAAAAAAA0GV/eRPSXxsYGNgtSjrhhBPy8MMP73btSSedlMcee2y3ry9evDiLFy9OkrzxjW/MXXfdtds1t9xyyy6/Pv/883P++efvdt3FF1+ciy+++BU/x6s1oat3BwAAAAAAAAAAAAAAAPgzMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAACAca9t214fYVx4tb+PYiYAAAAAAAAAAAAAAADGtf7+/mzZskXQ9Cq1bZstW7akv79/v+/RdwDPAwAAAAAAAAAAAAAAAK85M2bMyKZNm/Lb3/6268/6w44/ZLR/tOvP6ZX+/v7MmDFjv79fzAQAAAAAAAAAAAAAAMC4dtBBB2XmzJlFnjXcGc7w3OEiz/p7NKHXBwAAAAAAAAAAAAAAAADqIGYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoIi+Xh8AAAAAAP6mzhVJ55rePHt4tDfPBQAAAAAAAAAYx7yZCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUERfrw8AAAAAAAAAwN+BzhVJ55rePHt4tDfPBQAAAADggPNmJgAAAAAAAAAAAAAAAKAIb2YCAAAAAAAAAKiZN68BAAAAUJA3MwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEXsNWZqmqa/aZqHmqb5adM0P2+a5tISBwMAAAAAAAAAAAAAAADGl74xXPNckhPatt3WNM1BSf63aZrvtW374y6fDQAAAAAAAAAAAAAAABhH9hoztW3bJtn2518e9Oe/2m4eCgAAAAAAAAAAAAAAABh/mpdbpb1c1DQTk6xOcmSSf2vb9l/2cM3ZSc5Okmlvmvaec2859wAf9bWvs7GToYGhXh+jKtfeu75nz55z5GZ7V8TPd13sXRd718XedbF3XexdF3uX19M/f/f9V4bG9HLxLhi6sDfPrZif77rYuy72rou962LvunQ6X/Xf54X581hd7E0p/v1dF3vXxd51sXdd7F0Xe5fn/0emFD/fdal170uPv3R127aDe7tuTDHTzoub5g1JViT5x7ZtH/1b1w0ODrarVq0a833Hi+HOcIaHhnt9jKoMLPluz569+KSH7V0RP991sXdd7F0Xe9fF3nWxd13sXV5P//zd//EMp783Dx8e7c1zK+bnuy72rou962Lvuti7LsPDr/ff54X581hd7E0p/v1dF3vXxd51sXdd7F0Xe5fn/0emFD/fdal176ZpxhQzTdiXm7Zt+4cknSQn7ee5AAAAAAAAAAAAAAAAgErtNWZqmubwP7+RKU3TTEryoSSPdftgAAAAAAAAAAAAAAAAwPjSN4Zr3pTkP5qmmZiX46f/btv2nu4eCwAAAAAAAAAAAAAAABhv9hoztW37syRzC5wFAAAAAAAAAAAAAAAAGMfG8mYmYE86VySda3rz7OHR3jwXAAAAAAAAAAAAAADgVZjQ6wMAAAAAAAAAAAAAAAAAdRAzAQAAAAAAAAAAAAAAAEX09foAAAAAAAAAAAAAAABQnc4VSeea3jx7eLQ3zwWINzMBAAAAAAAAAAAAAAAAhYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAiujr9QEAAAAAAAAAAAAAAABg3OhckXSu6c2zh0d789x94M1MAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKCIvl4fAAAAAAAAAAAAAAAAYFzrXJF0runNs4dHe/Nc+Bu8mQkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFBEX68PAAAAAAAAAAAAQBd0rkg61/Tm2cOjvXkuAAAAr3nezAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIro6/UBAP4udK5IOtf05tnDo715LgAAAAAAAAAAAAAAHGDezAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAAAAAAAAAFCEmAkAAAAAAAAAAAAAAAAoQswEAAAAAAAAAAAAAAAAFCFmAgAAAAAAAAAAAAAAAIoQMwEAAAAAAAAAAAAAAABFiJkAAAAAAAAAAAAAAACAIsRMAAAAAAAAAAAAAAAAQBFiJgAAAAAAAAAAAAAAAKAIMRMAAAAAAAAAAAAAAABQhJgJAAAAAAAAAAAAAAAAKELMBAAAAAAAAAAAAAAAABQhZgIAAAAAAAAAAAAAAACKEDMBAAAAAAAAAAAAAAAARYiZAAAAAAAAAAAAAAAAgCLETAAAAAAAAAAAAAAAAEARYiYAAAAAAAAAAAAAAACgCDETAAAAAAAAAAAAAAAAUISYCQAAAAAAAAAAAAAAAChCzAQAAAAAAAAAAAAAAAAUIWYCAAAAAAAAAAAAAAAAihAzAQAAAAAAAAAAAAAAAEWImQAAAAAAAAAAAAAAAIAixEwAAAAAAAAAAAAAAABAEWImAAAAAAAAAAAAAAAAoAgxEwAAAAAAAADwf+zdMail6V3H8f8zOeoUWo0WiwZHiAghRSCXWNjc2DjaCEHBFIGAMtWIhc1u9y4it/OmSWmwSaKFFmICYsDXIFjs3WBhXAxBVggrqIhXG5GFx2YLWZM9Z3bm/p7Z8/98IJAlN/d5lh/vuXcHvvsCAAAAAESImQAAAAAAAAAAAAAAAICIozHTGOPDY4y/HGO8Mcb41hjjtxIXAwAAAAAAAAAAAAAAAM7L4YSvebuqfnvO+c0xxo9U1etjjL+Yc/79Hd8NAAAAAAAAAAAAAAAAOCNH38w05/znOec33/nv/1VVb1TVj9/1xQAAAAAAAAAAAAAAAIDzMuacp3/xGA+r6htV9bE553++6397XFWPq6oevPTgE0++/OT53fIDYn9zr8uHl6uv0crnv/7tZWd//PBHdXnSy83uwOUra85dzN6k+DzPW/p8f+Qtezfi+c7zfJPi+e7F3nn+eYwUz3ee39dI8Xz3Yu9e7J3n9/Ne7N2LvUnx8zvP892LP28hxed5L/bO83nei9/XerF3L/bOe/VTr74+57w49nUnx0xjjB+uqr+qqt+dc/7Je33txcXFvLm5Oen7npNt32q73FZfo5WHL3912dmfu//p2ur+msO32zXnLmZvUnye5y19vh+9Zu9GPN95nm9SPN+92DvPP4+R4vnO8/saKZ7vXuzdi73z/H7ei717sTcpfn7neb578ectpPg878XeeT7Pe/H7Wi/27sXeeWOMk2Kmeyd+sx+oqj+uqi8dC5kAAAAAAAAAAAAAAAAAvpejMdMYY1TV71fVG3PO37v7KwEAAAAAAAAAAAAAAADn6JQ3M/1cVX22qn5+jPG37/znl+74XgAAAAAAAAAAAAAAAMCZORz7gjnnX1fVCNwFAAAAAAAAAAAAAAAAOGOnvJkJAAAAAAAAAAAAAAAA4JmJmQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQMRh9QUAAAAAAGhov6rar9ecvd2uORcAAAAAAAAAb2YCAAAAAAAAAAAAAAAAMsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAACdpJ99AAAgAElEQVQAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABBxWH0BAHjh7FdV+/Was7fbNecCAAAAAAAAAAAAAAR4MxMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIg4rL4AAAAAAABw5varqv16zdnb7ZpzAQAAAAAAgO/Jm5kAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAg4rD6AgAAS+1XVfv1mrO32zXnAgAAAAAAAAAAAMAi3swEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQcVh9AQAAAAAAAAAAAOAZ7VdV+/Was7fbNecCAAAfSN7MBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAICIw+oLAAAA3In9qmq/XnP2drvmXAAAAAAAAAAAAHjBeTMTAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAg4rD6AgAAAAAAAAAAAAA8hf2qar9ec/Z2u+ZcAADOhjczAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIOJozDTG+OIY41/GGH+XuBAAAAAAAAAAAAAAAABwnk55M9MfVNWjO74HAAAAAAAAAAAAAAAAcOaOxkxzzm9U1b8H7gIAAAAAAAAAAAAAAACcsVPezAQAAAAAAAAAAAAAAADwzA7P6xuNMR5X1eOqqgcvPaht357Xt34qn//6t5ecW1X18Y+8tezvu6v/OKzbe6+3a6v/XnT4tubcxezdy9LP84O90zzfvfh9rRfPdy+e717s3YvP81483714vnvx5y29+Dzvxd69+Pndi717sXcvfn734vnuxd69+POWXvz87mXp5/mb9k7z87sXe/di7xfXmHMe/6IxHlbVn805P3bKN724uJg3NzfPdrP36eHLX11yblXV5x69Vtvltuz8jpbuff/TtdX9NYdvt2vOXczevdi7F3v34ve1XjzfvXi+e7F3Lz7Pe/F89+L57sXevfg878Xevfg878Xevdi7Fz+/e/F892LvXuzdi5/fvdi7F5/nvdi7F3vnjTFen3NeHPu6e4nLAAAAAAAAAAAAAAAAAByNmcYYX6mqv6mqnxljfHeM8et3fy0AAAAAAAAAAAAAAADg3ByOfcGc8zOJiwAAAAAAAAAAAAAAAADn7eibmQAAAAAAAAAAAAAAAACeBzETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiDisvgAAAMTsV1X79Zqzt9s15wIAAAAAAAAAAAC8QLyZCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACDisPoCAAAAAAAAAAAAAABU1X5VtV+vOXu7XXMuAO14MxMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABBxWH0BAAAAAAAAzsh+VbVfrzl7u11zLgAAAAAAACfzZiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABBxWH2Bs7JfVe3Xa87ebtecCwAAAAAAAAAAAAAAACfyZiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEYfVFwAAAAAAAAAAAEL2q6r9es3Z2+2acwEAAIAXijczAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAIAIMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACDisPoCAAAA8Mz2q6r9es3Z2+2acwEAAAAAAAAAAD6AvJkJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIOKw+gIAAAAAT2W/qtqv15y93a45FwAAAAAAAAAAzoSYCQAAAAAAAHh//MsGAAAAAACAp3Rv9QUAAAAAAAAAAAAAAACAHsRMAAAAAAAAAAAAAAAAQMRh9QUAAAAAAKqqar+q2q/XnL3drjkXAAAAAAAAAJo56c1MY4xHY4x/GGN8Z4zx8l1fCgAAAAAAAAAAAAAAADg/R2OmMcaHquoLVfWLVfXRqvrMGOOjd30xAAAAAAAAAAAAAAAA4Lyc8mamT1bVd+ac/zjn/J+q+sOq+uW7vRYAAAAAAAAAAAAAAABwbsac872/YIxfqapHc87feOevP1tVPzvnfPKur3tcVY+rqh689OATT7785P99r3O3v7nX5cPL1dcgxN692LsXe/di717s3Yu9e7F3L/buxd692LsXe/di717s3Yu9e7F3L/buxd692LsXe/di717s3cu+/05d1mHN4ZevrDm3Mc93L/buxd69dN371U+9+vqc8+LY150SM/1qVf3Cu2KmT845f/P7/X8uLi7mzc3NU175g2/bt9out9XXIMTevdi7F3v3Yu9e7N2LvXuxdy/27sXevdi7F3v3Yu9e7N2LvXuxdy/27sXevdi7F3v3Yu9e7N3Ltv1QbXV/0eG3a85tzPPdi717sXcvXfceY5wUM9074Xt9t6o+/H/++ieq6q33ezEAAAAAAAAAAAAAAACgp1Nipteq6qfHGD81xvjBqvq1qvrTu70WAAAAAAAAAAAAAAAAcG4Ox75gzvn2GONJVf15VX2oqr445/zWnd8MAAAAAAAAAAAAAAAAOCtHY6aqqjnn16rqa3d8FwAAAAAAAAAAAAAAAOCM3Vt9AQAAAAAAAAAAAAAAAKAHMRMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACIOqy8AAAAAAAAAAAAAAHwfl69UXW6rbwEA8Nx4MxMAAAAAAAAAAAAAAAAQIWYCAAAAAAAAAAAAAAAAIsRMAAAAAAAAAAAAAAAAQISYCQAAAAAAAAAAAAAAAIgQMwEAAAAAAAAAAAAAAAARYiYAAAAAAAAAAAAAAAAgQswEAAAAAAAAAAAAAAAARIiZAAAAAAAAAAAAAAAAgAgxEwAAAAAAAAAAAAAAABAhZgIAAAAAAAAAAAAAAAAixEwAAAAAAAAAAAAAAABAhJgJAAAAAAAAAAAAAAAAiBAzAQAAAAAAAAAAAAAAABFiJgAAAAAAAAAAAAAAACBCzAQAAAAAAAAAAAAAAABEiJkAAAAAAAAAAAAAAACACDETAAAAAAAAAAAAAAAAECFmAgAAAAAAAAAAAAAAACLETAAAAAAAAAAAAAAAAECEmAkAAAAAAAAAAAAAAACIEDMBAAAAAAAAAAAAAAAAEWImAAAAAAAAAAAAAAAAIELMBAAAAAAAAAAAAAAAAESImQAAAAAAAAAAAAAAAICIMed8/t90jH+tqn967t/4xfejVfVvqy9BjL17sXcv9u7F3r3Yuxd792LvXuzdi717sXcv9u7F3r3Yuxd792LvXuzdi717sXcv9u7F3r3Yuxd792LvXuzdi7176br3T845f+zYF91JzNTVGONmznmx+h5k2LsXe/di717s3Yu9e7F3L/buxd692LsXe/di717s3Yu9e7F3L/buxd692LsXe/di717s3Yu9e7F3L/buxd692LsXe7+3e6svAAAAAAAAAAD8b3t3HqxJVZ9x/PsMy4Rx2GRHQBQkIiWyCRo0oqCgUUDRaDAoWq4oblECoiHGDSiNhRKMrBoNGAFZJEAAFzAxwCjr4KAUQdkyCCrgiAswv/zRPXK5zGi8vO/tud3fT9XUdHVPUU9xqvuc96ySJEmSJEmSNAwuZpIkSZIkSZIkSZIkSZIkSZIkSZI0LVzMNFrHdh1A08ryHhbLe1gs72GxvIfF8h4Wy3tYLO9hsbyHxfIeFst7WCzvYbG8h8XyHhbLe1gs72GxvIfF8h4Wy3tYLO9hsbyHxfIeFst7WCzvYbG8h8XyHhbL+/dIVXWdQZIkSZIkSZIkSZIkSZIkSZIkSdIAeDKTJEmSJEmSJEmSJEmSJEmSJEmSpGnhYiZJkiRJkiRJkiRJkiRJkiRJkiRJ08LFTJIkSZIkSZIkSZIkSZIkSZIkSZKmxYpdB5BmoiTrVtVPus4habSSPAvYEZhfVRd0nUfSo5NkR6Cqal6SpwB7ANdX1bkdR5MkSZIkqTeSPBl4HHBZVS2acH+Pqjq/u2SaDo6XSFI/+D2XJElavrT9LXvR9LkUcDtwdlUt6DSYJEnSCHky0xQkeWKSE5N8JMncJMclmZ/k1CSbdp1Po5XksZP+rAVcnmTNJI/tOp/GI42dkrwsyUvb63SdS6OV5PIJ128EjgZWBQ5LcnBnwTR2SdZJsm2SpyaZ23UejV6Sw4BPA59N8nGa93sucHCSQzsNp5FL8vYka7fXmye5JMndSS5L8tSu82m0LG9pWNr3fJ92YbJ6JMkeE65XT3JCkmuSnJxkvS6zafSSXJHkA0k26zqLxi/JDkm+meRLSTZOcmGSe5LMS7Jt1/k0WkneAZwFHAjMT7LXhMcf6yaVxsXxkmFKMivJrPZ65STbWd79Y/t8WPyeC5oFbF1n0HglWWkp99buIovGK8mKE67ntr/L/Z4PQJIfdp1B45Hkb4EvAwEuB+a116c4n2lYkpzXdQaNn9/z/kqyQpI3J/lwkp0nPftAV7k0HvavTU2qqusMM06SS4BTgNWBvwZOAr4CvAB4dVU9r8N4GrEki4EfT7q9EXArzWkPT5z+VBqnJC8AjgFuAG5rb28EbA4c4Ik9/ZHkyqratr2eB7yoqu5M8hjg0qpyQnTPtJNgPw1sCmwCXAmsC1wMvLOq7ukunUYpybXANsBsYCGwUVXdm2QVmp2it+40oEYqyXVVtVV7/e/A8VV1RpJdgI9W1c6/9z+gGcXyHp4kqwGH0LTJz6uqkyc8O6aqDugsnEYuyTeBV1TVXUn2Az4IXALsBBxbVZ/pNKBGJskVVbVde308TZvtOOBlwHOqau8u82m0ktwEnA78JU1ZnwL8W1Xd3mkwjUW7ecxhwBrAkcC7q+q0JLsCH6mqZ3YaUCPV/v5+ZlUtSrPZ22nAF6vqqIl9b+oHx0uGJ8newOeAxcBbgPcDvwS2AN5aVV/rMJ5GyPb5sPg9H56lLGoI8D1gW5p5Qz+b/lQalyTPBb5IM0Z2JfCmqvpR++x333v1Q5L9gU8CPwXeCfwTcBNNe+2gqjqlu3QapSS/oDmdB5rvOMAc4D6a+nu1ToJpLNqFDVtV1f2T7q8MXFdVT+ommcYhybLq5gDnVNUG05lH4+X3fFjaPpY5NAtT9wMurqr3tM9sm/eM/WtTs+If/idailWr6rMASQ6oqk+2909I8vYOc2k8DgJ2A95XVddCMwGjqp7QbSyN0VHAbks69JZI8gTgXGDLLkJpLGYlWZPmpMJU1Z0AVfXLJA90G01jciLw2qr6QZIdgbdV1U5pTuY6AXh5t/E0Qg9U1YPAfUlurKp7AarqV+1Arfpl4u+adavqDICq+laSVTvKpPGxvIfnJJqNBk4HXp9kH2DfqvoN8IxOk2kc1qmqu9rrd9BMjv5pkjnApYCLmfpph6rapr3+VJLXdppG4/Dzqnov8N4kzwb+CrgiyQLglKo6ttt4GrGVquo8gCRHVNVpAFX19SSf6DaaxmCFqloEUFU/ajcZOC3J43loMF794XjJ8BwGPA1YBbgaeHrbt/p4mt9oLmbqJ9vn/ef3fHju4pEL2B4HXEEzkdIFbP1yJLB7VV2X5OXAhUn2q6pLsY3eR38D/CmwKk17bduqurHd+f1Cmg1l1A+fp9l4/X1VdQdYf/fcYmBDHll/b9A+U7/Mo9mEeWn19BrTnEXj93n8ng/Jjks23E5yNHBMkq/SjJPZNu83+9f+n1zMNDWLk2xBU6HMSbJDVX03yebACh1n04hV1SeSfJnmY3ILzcCNR5r124o0O49NdhvwiKPYNaOtTrPrWIBKsn5VLUwyFxuLfbVKVf0AoKouT/LP7fVxSd7dbTSN2G+TzKmq+4Dtl9xMsjp27vXRaUk+D/wDcEaSdwFfBXYFbu4ymMbC8h6ezapqn/b6zCSHAt9IsmeXoTQ29yd5XFXdBiyi2fUd4DfY59I36yZ5D81vr9WSpB46Qn5Wh7k0ZlX1beDbSQ4Eng+8EnAxU7/8uj35fHWa/pa9q+rMJM8BHuw4m0ZvYZJtquoqgPaEphfTbCjjqec943jJMFXVQoAkN0/oW/1xEtts/WL7fEAmfc9vBf4Ov+d95wK2YVm5qq4DaE/JXQB8NcnB+K730YPt5lB3JVlUVTcCVNUdiVMe+qSqDkyyPXBKkjOBo/Gd7rN3AV9PcgNwS3tvE2BzwM32+2cB8OaqumHyg7b/RT3i93xwVl5yUVUPAG9KchjwDWBuZ6k0LvavTYGLmabmIJqdxhYDewOHJNmaZnD2TV0G03hU1a3AK5K8hGbnkjkdR9J4nQjMazvxl/wg2Bh4Fc3JLeqJqtp0GY8WAy+dxiiaPjcm+SDwdZrjO68CSLIStov65s/bEzuoqomLl1YC3OmgZ6rq0CT70+wutxkwm6Zdfibw6g6jaQws70GanWTWku95VX20nWhzCXbw9dG7gQuSnA5cR7Nw7Xzg2TSndKk/jqPZMRbgC8DawJ1J1qdtp6tXfjj5RnuS6vntH/XLW2h2Al8M7A68tV2Mfhvwxg5zaTxeAzzshPN2UPY1ST7XTSSNk+MlwzPh99jrJ9xbgQmTMdQLts8Hxu/5sLggeXDuX7KJJ0B7QtOuwDk0ferql5uTfJymHr8+ySdpNoDbDfjfTpNp5Krqe0l2o1nMcjHwJx1H0phU1fntZvs70pymGJqNuee1/arql79n2ZPcD5zGHJomfs8H5btJ9qiq342FVdWHktwGfLbDXBoP+9emIA8t+NKjkeQcYM9Jk2XVQ0meDTwHuLyqLug6j8YjyZbAXjz8B+HZVfX9ToNJelSSrAG8H3gKcDVweFX9oj2tZ8uqurTTgJKmJMnKNIuOb6+qi5K8Gvgz4PvAsVV1f6cBNXJJdgSqquYl2QrYA1hQVed2HE1jkORI4IKqumjS/T2Az1TVk7pJpnFp22b7Alvw0Mm5Z1XV9Z0G08gleTLN7+7LqmrRhPsP69RXPyTZjGbjkI1pFj7cAJxSVfd0Gkxj0fatbYjvt9Q7E+tvmtPWNquq+b7f/ZTk6cC1VfXrSfc3BZ5VVV/qIpfGL8mzaCZOznc8tJ8mtc8fBG4C/sX2ef+1C9gOBTatqvW7zqPRayfG3llVV0+6vzrw9qr6aDfJNA5JVgPeRrNA8Wia8ZL9gZuBD1eVC5p6YinjofsBHwI+ARzneKg0cyXZiWas+94kqwCHANvSzHf4mG30fkuyAc1v77W6zqLRSzIbeCUP1d/70sxnWkBTf/+204AaqfZ7fn1V3ZNkDnAwfs//IBczTUGSs5dy+3k0x75RVXtObyKNU5LLq2rH9vqNwAE0u76/APhaVR3eZZsTYQsAAAbDSURBVD5JkqShS/KvNJPd5wB3A48BzgB2pfnN42lcPdIeuf1CmjK/kGZizcU0uwz+hwOxw5LkdVXlaT3SDJTkQJod5xYA2wDvrKqz2mdXVNV2XebTaCV5B/ASmjr7RTS7j/2cZvLkAVX1re7SadTa8j4AuB7fb6lX2vf7bVh/S70zaTz0DTRt9TNwPLSXbJ+rnSS7ZEGy/WuSNAM4Hir1V5LrgKdV1QNJjgXuA06jeb+fVlUv6zSgRsr558OylPp7Ls0pmrsCVNX+nYXTyPk9nxoXM01BkiuB64DjaXa2CHAKze4HVNXF3aXTqCW5sqq2ba/nAS+qqjuTPAa4tKqe2m1CTack51XVC7vOIWlq2h3HDqE5eW3d9vZPgLNoTmm6u6tskqYuyTVVtXWSFYHbgA2r6sEkAa6uqq07jqgRSnItzaS52cBCYKMJu1RdZnkPS5Kbq2qTrnNodCa01/YG1mlv217rofZ7/syqWtTu7H8a8MWqOmpiX4z6YUn93bbR5gDnVtUuSTahOXnN8u4R32+pv3y/h6fd6f8QYCPgvKo6ecKzY6rqgM7CaaQcDx0W2+eayP61/rH+HpZJ/anr0sxjsz+1hxwPlforyYKq2rK9fthmMUmuqqptukunUUtyBc0pLc4/HwDr72Hxez41s7oOMENtD3yP5ujte9qdiX5VVRdbkfTSrCRrJlmLZgHgnQBV9UvggW6jaRySbLeMP9vTTJyVNHN9hWZ3wedW1VrtEb3Pbe+d2mkySY/GrCQrA6vS7Gayent/NrBSZ6k0Lg9U1YNVdR9wY1XdC1BVvwIWdxtN45DkmmX8uRZYr+t8Grkl7bVdJrXX7sb2Wt+sUFWLAKrqR8AuwAuT/CPNwI36Z8X279k07Taq6mZsr/WR77fUX77fw3MSTdmeDrwqyelJZrfPntFdLI2B46HDY/t8QOxfGxzr72GZ2J/6WPtTe83xUKm/5id5XXt9dZIdAJJsAdzfXSyNyQ44/3xIrL+Hxe/5FKz4h/+JJquqxcCnkpza/n0H/r/ss9VpGg8BKsn6VbUwyVwcnOurecDFLL1815jmLJJGa9OqOmLijapaCByR5PUdZZL06J0AXA+sQNPhc2qS/6EZlPtyl8E0Fr9NMqddzLT9kpvt7oMuZuqn9YDdaQZkJwrwnemPozFbVnvt8Akdf+qHhUm2qaqrANoTHl4MnAi463v/HA/MS3Ip8OfAEQBJ1gF+1mUwjYXvt9Rfvt/Ds1lV7dNen5nkUOAbSfbsMpTGwvHQYbF9Pjz2rw2L9few2J86HI6HSv31BuCoJB8A7gL+O8ktwC3tM/WI888Hx/p7WPyeT0GqqusMM16SvwB2rqr3d51F0yfJHGC9qrqp6ywarSTzgZdW1Q1LeXZLVW3cQSxJI5DkAuAi4AtVdUd7bz1gf+D5VbVbh/EkPQpJNgSoqtuTrAHsBtxcVZd3m0yjlmR2Vf1mKffXBjaoqms7iKUxSnICcFJV/edSnp1cVft2EEtjYnttOJJsRHPa3sKlPNu5qv6rg1gaoyRbAVsC86vq+q7zaHx8v6X+8v0eniQLgK3aiTZL7r0WOAiYW1WP7yycpoXjof1l+3xY7F8bFuvvYbE/dVgcD5X6LcmqwBNpFrbcuuS7rn5z/nn/WX8Pj9/zP46LmSRpkiQvB66tqh8s5dneVXVmB7EkjUCSNYGDgb2AddvbdwBnA4dX1eQd6SRJkjSNbK9JkiRJy48kRwIXVNVFk+7vAXymqp7UTTJJkrQs1t/DYn+qJEmSpJnMxUyS9EdI8rqqOqnrHJJGz/dbkiRp+WZ7TZIkSVp+2D6XJGnmsf4eFstbkiRJ0vLOxUyS9EdIcnNVbdJ1Dkmj5/stSZK0fLO9JkmSJC0/bJ9LkjTzWH8Pi+UtSZIkaXm3YtcBJGl5k+SaZT0C1pvOLJJGy/dbkiRp+WZ7TZIkSVp+2D6XJGnmsf4eFstbkiRJ0kzmYiZJeqT1gN2Bn0+6H+A70x9H0gj5fkuSJC3fbK9JkiRJyw/b55IkzTzW38NieUuSJEmasVzMJEmPdA4wt6qumvwgybemP46kEfL9liRJWr7ZXpMkSZKWH7bPJUmaeay/h8XyliRJkjRjpaq6ziBJkiRJkiRJkiRJkiRJkiRJkiRpAGZ1HUCSJEmSJEmSJEmSJEmSJEmSJEnSMLiYSZIkSZIkSZIkSZIkSZIkSZIkSdK0cDGTJEmSJEmSJEmSJEmSJEmSJEmSpGnhYiZJkiRJkiRJkiRJkiRJkiRJkiRJ08LFTJIkSZIkSZIkSZIkSZIkSZIkSZKmxf8BDKlC6Ejh3zAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 4320x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkUVFl_8IjlS",
        "colab_type": "code",
        "outputId": "aa0d19a7-2b7f-41fe-8a81-9000ecf15d41",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = df.iloc[:, [0, 5]]\n",
        "y = df.iloc[:, 7]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "LoGscores = []\n",
        "DTscores = []\n",
        "RFscores = []\n",
        "SVscores = []\n",
        "\n",
        "\n",
        "############### DT ###########################################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "############### DT ###########################################\n",
        "from sklearn import tree\n",
        "DTclf=tree.DecisionTreeClassifier()\n",
        "\n",
        "############### RF ############################################\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFclf=RandomForestClassifier(n_estimators=11)\n",
        "\n",
        "######################### SVM ##################################\n",
        "from sklearn.svm import SVC\n",
        "SVclf = SVC(kernel='poly', degree=4)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=2, shuffle=True)\n",
        "for train_index, test_index in cv.split(X):\n",
        "    print(\"Train Index: \", train_index, \"\\n\")\n",
        "    print(\"Test Index: \", test_index)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
        "\n",
        "    ############# for LoG #################\n",
        "    logreg.fit(X_train, y_train)\n",
        "    LoGscores.append(logreg.score(X_test, y_test))\n",
        "    ############# for DT #################\n",
        "    DTclf.fit(X_train, y_train)\n",
        "    DTscores.append(DTclf.score(X_test, y_test))\n",
        "    ############# for RF #################\n",
        "    RFclf.fit(X_train, y_train)\n",
        "    RFscores.append(RFclf.score(X_test, y_test))\n",
        "    ############# For SVM #################\n",
        "    SVclf.fit(X_train, y_train)\n",
        "    SVscores.append(SVclf.score(X_test, y_test))\n",
        "    \n",
        "\n",
        "\n",
        "import numpy as np\n",
        "print('Logistic Reg.  scores:', np.mean(LoGscores))\n",
        "print('Decision Tree scores:', np.mean(DTscores))\n",
        "print('Random Forest scores:', np.mean(RFscores))\n",
        "print('SVM scores:', np.mean(SVscores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Index:  [  1   4   6   7   8   9  10  11  13  15  16  17  18  19  20  21  22  23\n",
            "  26  27  29  30  31  32  33  34  35  37  38  39  40  41  42  43  45  46\n",
            "  47  49  50  51  52  53  56  57  58  59  60  62  63  64  66  67  68  69\n",
            "  70  71  72  73  74  75  76  77  78  79  80  81  83  85  87  88  89  90\n",
            "  91  92  93  95  96  98  99 100 101 102 103 104 105 107 111 112 113 114\n",
            " 115 116 117 118 119 120 121 124 125 126 127 128 129 130 131 132 133] \n",
            "\n",
            "Test Index:  [  0   2   3   5  12  14  24  25  28  36  44  48  54  55  61  65  82  84\n",
            "  86  94  97 106 108 109 110 122 123]\n",
            "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  12  14  15  17  18  19  20\n",
            "  22  24  25  26  28  31  32  33  34  36  37  38  39  40  42  43  44  46\n",
            "  47  48  49  50  51  52  54  55  56  57  58  60  61  62  63  65  66  67\n",
            "  68  69  70  72  73  75  76  79  80  82  83  84  85  86  87  88  89  90\n",
            "  91  93  94  95  96  97  99 101 102 103 104 105 106 107 108 109 110 111\n",
            " 112 113 114 115 116 118 119 120 122 123 124 125 126 129 130 131 133] \n",
            "\n",
            "Test Index:  [ 11  13  16  21  23  27  29  30  35  41  45  53  59  64  71  74  77  78\n",
            "  81  92  98 100 117 121 127 128 132]\n",
            "Train Index:  [  0   2   3   4   5   7   8  11  12  13  14  15  16  20  21  22  23  24\n",
            "  25  27  28  29  30  31  33  34  35  36  37  38  39  41  42  43  44  45\n",
            "  46  47  48  49  50  51  52  53  54  55  58  59  61  63  64  65  66  67\n",
            "  68  69  70  71  72  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
            "  88  90  92  94  95  97  98  99 100 102 103 104 106 107 108 109 110 111\n",
            " 113 114 116 117 118 119 120 121 122 123 124 125 127 128 129 132 133] \n",
            "\n",
            "Test Index:  [  1   6   9  10  17  18  19  26  32  40  56  57  60  62  73  87  89  91\n",
            "  93  96 101 105 112 115 126 130 131]\n",
            "Train Index:  [  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  34  35  36  37\n",
            "  39  40  41  42  43  44  45  47  48  49  51  53  54  55  56  57  59  60\n",
            "  61  62  63  64  65  67  71  72  73  74  75  77  78  81  82  84  85  86\n",
            "  87  89  90  91  92  93  94  95  96  97  98 100 101 102 104 105 106 107\n",
            " 108 109 110 112 115 116 117 121 122 123 126 127 128 129 130 131 132] \n",
            "\n",
            "Test Index:  [  8  33  38  46  50  52  58  66  68  69  70  76  79  80  83  88  99 103\n",
            " 111 113 114 118 119 120 124 125 133]\n",
            "Train Index:  [  0   1   2   3   5   6   8   9  10  11  12  13  14  16  17  18  19  21\n",
            "  23  24  25  26  27  28  29  30  32  33  35  36  38  40  41  44  45  46\n",
            "  48  50  52  53  54  55  56  57  58  59  60  61  62  64  65  66  68  69\n",
            "  70  71  73  74  76  77  78  79  80  81  82  83  84  86  87  88  89  91\n",
            "  92  93  94  96  97  98  99 100 101 103 105 106 108 109 110 111 112 113\n",
            " 114 115 117 118 119 120 121 122 123 124 125 126 127 128 130 131 132 133] \n",
            "\n",
            "Test Index:  [  4   7  15  20  22  31  34  37  39  42  43  47  49  51  63  67  72  75\n",
            "  85  90  95 102 104 107 116 129]\n",
            "Logistic Reg.  scores: 0.5284900284900285\n",
            "Decision Tree scores: 0.48433048433048426\n",
            "Random Forest scores: 0.4621082621082621\n",
            "SVM scores: 0.27521367521367524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hudcDMfaIjlU",
        "colab_type": "code",
        "outputId": "5234a8c1-8b8f-428b-d795-0a0e39700601",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#read csv file\n",
        "x = df[['MONTH','YEAR','HUMIDITY', 'MIN', 'RAINFALL', 'MAX']]\n",
        "y = df['LEVEL']\n",
        "\n",
        "model = svm.SVC()\n",
        "accuracy = cross_val_score(model, x, y, scoring='accuracy', cv = 11)\n",
        "print(accuracy)\n",
        "#get the mean of each fold \n",
        "print(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=11.\n",
            "  % (min_groups, self.n_splits)), Warning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.26666667 0.33333333 0.66666667 0.5        0.5        0.45454545\n",
            " 0.63636364 0.63636364 0.6        0.4        0.4       ]\n",
            "Accuracy of Model with Cross Validation is: 49.03581267217631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\Users\\FAZLY\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDEMO3NKIjlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pdUuj6RIjlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}